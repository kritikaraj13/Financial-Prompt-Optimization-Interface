{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eba91b3-f5be-4f76-9667-7b9f409ec6f9",
   "metadata": {},
   "source": [
    "# Financial Prompt Optimization Interface\n",
    "## Explaining the \"Financial Prompt Optimization Interface\" Project\n",
    "\n",
    "**Project Goal:** To create a system that takes a natural language financial analysis request and transforms it into a highly optimized, structured, and regulatory-compliant prompt, suitable for a specialized financial LLM. This system will enforce specific output formats and integrate with LangSmith for traceability and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2bbc97-bfec-4812-869f-f1fe0c2df998",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Phase 1: Establishing the Financial Intelligence Core: Environment, Rules, and Dynamic Entity Mapping\n",
    "\n",
    "**What it is:**\n",
    "This is the foundational stage of our project. It's where we set up our development environment, install necessary tools, define our core financial domain knowledge (like compliance rules and company mappings), and establish the initial \"data backbone\" that our AI system will rely on.\n",
    "\n",
    "**Why it's needed:**\n",
    "*   **Foundation:** Just like building a house, you need a strong foundation. This phase ensures all our tools are ready and our system understands the specific language and rules of finance.\n",
    "*   **Domain Specificity:** Financial analysis isn't generic. It requires knowledge of regulations, company names, and specific financial tasks. This phase injects that crucial domain-specific intelligence.\n",
    "*   **Dynamic Data:** Financial markets change! We need a way to look up information (like stock tickers) dynamically, not just rely on a static list.\n",
    "\n",
    "**How it works (Code Meaning):**\n",
    "\n",
    "1.  **`1.1. Environment Setup & Dependencies`**\n",
    "    *   `!pip install ...`: This command installs all the Python libraries our project needs: `transformers` (often used with LLMs, though not directly in our current simple mock LLM setup), `langchain` (for building the AI pipeline), `langsmith` (for observability), `openai` (if we were to use a real OpenAI LLM), `requests` (for making API calls to FMP), and `pandas` (for making output tables nice).\n",
    "    *   `import os, re, json, datetime, requests, pandas`: These lines bring in modules for interacting with the operating system (environment variables), regular expressions (pattern matching), JSON data handling, date/time operations, web requests, and data tables.\n",
    "    *   `os.environ[...] = \"...\"`: This is critical. It sets up environment variables for API keys (`LANGCHAIN_API_KEY`, `FMP_API_KEY`) and LangSmith project name. These keys allow our system to communicate with external services (like LangSmith for tracing, and FMP for financial data).\n",
    "    *   `from langsmith import traceable ...`: These import specific tools from LangSmith and LangChain for building our AI chain. `@traceable` is particularly important; it tells LangSmith to record the execution of the function it decorates.\n",
    "\n",
    "2.  **`1.2. Data Discovery: Define Domain-Specific Knowledge Base & Rules`**\n",
    "    *   **`COMPLIANCE_RULES`:** This is a Python dictionary that acts as our \"rulebook.\"\n",
    "        *   **Keys:** Represent the different types of financial analysis (e.g., `\"stock_analysis\"`, `\"quarterly_report_summary\"`).\n",
    "        *   **Values:** Are themselves dictionaries containing:\n",
    "            *   `\"rule_name\"`: The specific regulatory rule (e.g., \"SEC Rule 13f\"). This is crucial for compliance.\n",
    "            *   `\"description\"`: A brief explanation of the rule.\n",
    "            *   `\"tasks_template\"`: A list of specific sub-tasks the LLM *must* perform for this type of analysis. This ensures the output is comprehensive and consistent. We added a \"(d) Concise narrative summary\" here to tell the LLM to generate human-like text *within* the structured output.\n",
    "            *   `\"output_format_spec\"`: The exact JSON structure the LLM is expected to return. This is vital for machine readability and strict compliance.\n",
    "    *   **`ENTITY_MAPPINGS`:** This dictionary serves as a local \"cache\" or initial lookup table for common company names and their stock ticker symbols (e.g., `\"apple\": \"AAPL\"`). It's pre-populated for speed.\n",
    "    *   **`INTENT_MAPPINGS`:** This is a dictionary that maps common keywords or phrases from user queries to our predefined financial intents.\n",
    "        *   **Keys:** Phrases users might type (e.g., \"financial report\", \"bond analysis\", \"long-term outlook\").\n",
    "        *   **Values:** Our internal, standardized intent labels (e.g., \"quarterly_report_summary\", \"fixed_income_analysis\"). This was significantly expanded using insights from your synthetic dataset to cover diverse phrasing.\n",
    "    *   **`get_current_quarter_year()`:** A simple function to automatically figure out the current financial quarter and year (e.g., \"Q3-2024\"). This makes the system more dynamic.\n",
    "    *   **`get_ticker_from_name(company_name: str)`:** This is our **dynamic lookup mechanism**.\n",
    "        *   It first checks if the `company_name` is already in our local `ENTITY_MAPPINGS` cache (fast lookup).\n",
    "        *   If not found, it makes an API call to **Financial Modeling Prep (FMP)** using your `FMP_API_KEY`. FMP's API searches for the company name and returns its ticker.\n",
    "        *   If found via FMP, it adds the new mapping to our `ENTITY_MAPPINGS` cache for future faster access.\n",
    "        *   `@traceable(run_type=\"tool\")`: LangSmith will record every time this function is called, showing the input (company name) and output (ticker or None).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdfa5f8-bc17-4d4c-9b8d-001a113e0938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Environment Setup & Data Definition ---\n",
      "1.1. Installing dependencies...\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langsmith in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.4.4)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.3.68)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: openai in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.93.2)\n",
      "Collecting openai\n",
      "  Downloading openai-1.95.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langsmith) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langsmith) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langsmith) (0.23.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (8.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langsmith-0.4.5-py3-none-any.whl (367 kB)\n",
      "Downloading openai-1.95.0-py3-none-any.whl (755 kB)\n",
      "   ---------------------------------------- 0.0/755.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/755.6 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 524.3/755.6 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 755.6/755.6 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: openai, langsmith\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.93.2\n",
      "    Uninstalling openai-1.93.2:\n",
      "      Successfully uninstalled openai-1.93.2\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.4.4\n",
      "    Uninstalling langsmith-0.4.4:\n",
      "      Successfully uninstalled langsmith-0.4.4\n",
      "Successfully installed langsmith-0.4.5 openai-1.95.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1.1. Environment Setup & Dependencies\n",
    "print(\"--- Phase 1: Environment Setup & Data Definition ---\")\n",
    "print(\"1.1. Installing dependencies...\")\n",
    "\n",
    "# Install necessary libraries (run only once or if not installed)\n",
    "!pip install transformers langchain langsmith \"langchain-core\" \"langchain-community\" openai requests pandas --upgrade\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests # For making HTTP requests to FMP API\n",
    "import pandas as pd # For visualization in Phase 3\n",
    "\n",
    "# LangSmith setup\n",
    "from langsmith import traceable\n",
    "from langsmith import Client\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8373d625-04fd-4d29-b144-51c9f5e82d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment setup complete. Remember to replace YOUR_API_KEY placeholders if you haven't!\n",
      "\n",
      "1.2. Defining Domain-Specific Knowledge Base and Rules...\n",
      "Domain knowledge base and rules defined.\n",
      "Dynamic ticker lookup (FMP API) function enabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- IMPORTANT: Set your API Keys ---\n",
    "# Replace with your actual keys. LangSmith is required for tracing.\n",
    "# OpenAI (or another LLM provider like Anthropic, HuggingFace) is optional for a real LLM simulation.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\" # <--- REPLACE THIS\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"FinancialPromptOptimizer\" # Name for your LangSmith project\n",
    "\n",
    "# Optional: If you want to use a real LLM (e.g., OpenAI's GPT-3.5-turbo) for simulation\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\" # <--- REPLACE THIS (if using OpenAI)\n",
    "\n",
    "# --- FMP API Key for dynamic entity mapping ---\n",
    "os.environ[\"FMP_API_KEY\"] = \"eSh1n1sIORuAqD4k40d0b9iqetqXovNe\" # <--- REPLACE THIS with your FMP API Key!\n",
    "\n",
    "print(\"\\nEnvironment setup complete. Remember to replace YOUR_API_KEY placeholders if you haven't!\")\n",
    "\n",
    "# 1.2. Data Discovery: Define Domain-Specific Knowledge Base & Rules\n",
    "print(\"\\n1.2. Defining Domain-Specific Knowledge Base and Rules...\")\n",
    "\n",
    "COMPLIANCE_RULES = {\n",
    "    \"stock_analysis\": {\n",
    "        \"rule_name\": \"SEC Rule 13f\",\n",
    "        \"description\": \"Requires institutional investment managers to report their security holdings.\",\n",
    "        \"tasks_template\": [\n",
    "            \"(a) 5-year volatility trend\",\n",
    "            \"(b) ESG risk exposure\",\n",
    "            \"(c) Institutional ownership changes\",\n",
    "            \"(d) Concise narrative summary of key findings.\"\n",
    "        ],\n",
    "        \"output_format_spec\": \"JSON with {metrics: [], risk_assessment: {}, compliance_check: bool, narrative: string}\"\n",
    "    },\n",
    "    \"quarterly_report_summary\": {\n",
    "        \"rule_name\": \"GAAP Principles (General Accounting)\",\n",
    "        \"description\": \"Adherence to generally accepted accounting principles for financial statements.\",\n",
    "        \"tasks_template\": [\n",
    "            \"(a) Revenue and Net Income trends (QoQ, YoY)\",\n",
    "            \"(b) Key balance sheet items (Assets, Liabilities, Equity)\",\n",
    "            \"(c) Cash flow analysis (Operating, Investing, Financing)\",\n",
    "            \"(d) Concise narrative summary of key findings and outlook.\"\n",
    "        ],\n",
    "        \"output_format_spec\": \"JSON with {summary: {}, financials: {}, narrative: string, compliance_check: bool}\"\n",
    "    },\n",
    "    \"fixed_income_analysis\": {\n",
    "        \"rule_name\": \"FINRA Rule 2210 (Communications with the Public)\",\n",
    "        \"description\": \"Ensures communications about bonds are fair and balanced, avoiding exaggerated claims.\",\n",
    "        \"tasks_template\": [\n",
    "            \"(a) Bond issuer's credit rating (e.g., S&P, Moody's)\",\n",
    "            \"(b) Current yield and yield to maturity (YTM)\",\n",
    "            \"(c) Bond covenants and call provisions\",\n",
    "            \"(d) Overall assessment narrative.\"\n",
    "        ],\n",
    "        \"output_format_spec\": \"JSON with {bond_details: {}, risk_factors: {}, compliance_notes: string, overall_assessment: string}\"\n",
    "    },\n",
    "    \"sector_analysis\": {\n",
    "        \"rule_name\": \"SEC Regulation Fair Disclosure\",\n",
    "        \"description\": \"Prohibits selective disclosure of material information\",\n",
    "        \"tasks_template\": [\n",
    "            \"(a) Sector performance vs. broader market\",\n",
    "            \"(b) Key growth drivers in the sector\",\n",
    "            \"(c) Regulatory risk factors\",\n",
    "            \"(d) Market commentary and future outlook.\"\n",
    "        ],\n",
    "        \"output_format_spec\": \"JSON with {sector_metrics: [], top_performers: [], risk_factors: {}, commentary: string}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "ENTITY_MAPPINGS = {\n",
    "    # Tech\n",
    "    \"tesla\": \"TSLA\", \"apple\": \"AAPL\", \"microsoft\": \"MSFT\", \"google\": \"GOOGL\",\n",
    "    \"alphabet\": \"GOOGL\", \"amazon\": \"AMZN\", \"nvidia\": \"NVDA\", \"meta\": \"META\",\n",
    "    \"adobe\": \"ADBE\", \"salesforce\": \"CRM\", \"intel\": \"INTC\", \"amd\": \"AMD\",\n",
    "    \"cisco\": \"CSCO\", \"oracle\": \"ORCL\", \"netflix\": \"NFLX\", \"dis\": \"DIS\", # Added DIS from CSV\n",
    "    \n",
    "    # Healthcare\n",
    "    \"johnson & johnson\": \"JNJ\", \"pfizer\": \"PFE\", \"merck\": \"MRK\", \"abbvie\": \"ABBV\",\n",
    "    \"eli lilly\": \"LLY\", \"novo nordisk\": \"NVO\", \"thermo fisher\": \"TMO\",\n",
    "    \n",
    "    # Financials\n",
    "    \"jpmorgan\": \"JPM\", \"goldman sachs\": \"GS\", \"visa\": \"V\", \"mastercard\": \"MA\",\n",
    "    \"bank of america\": \"BAC\", \"wells fargo\": \"WFC\", \"morgan stanley\": \"MS\",\n",
    "    \"charles schwab\": \"SCHW\",\n",
    "    \n",
    "    # Consumer Goods\n",
    "    \"walmart\": \"WMT\", \"procter & gamble\": \"PG\", \"coca cola\": \"KO\", \"pepsi\": \"PEP\",\n",
    "    \"mcdonald's\": \"MCD\", \"starbucks\": \"SBUX\", \"costco\": \"COST\",\n",
    "    \n",
    "    # Industrials/Energy\n",
    "    \"exxon mobil\": \"XOM\", \"chevron\": \"CVX\", \"boeing\": \"BA\", \"lockheed martin\": \"LMT\",\n",
    "    \"raytheon\": \"RTX\", \"nextera energy\": \"NEE\", \"ford\": \"F\", # Added Ford from CSV\n",
    "}\n",
    "\n",
    "# --- UPDATED INTENT_MAPPINGS based on your synthetic dataset analysis ---\n",
    "INTENT_MAPPINGS = {\n",
    "    # --- Stock Analysis ---\n",
    "    \"stock analysis\": \"stock_analysis\", \"analyze stock\": \"stock_analysis\",\n",
    "    \"company performance\": \"stock_analysis\", \"equity analysis\": \"stock_analysis\",\n",
    "    \"investment review\": \"stock_analysis\", \"stock insights\": \"stock_analysis\",\n",
    "    \"share performance\": \"stock_analysis\", \"how is doing\": \"stock_analysis\",\n",
    "    \"tell me about\": \"stock_analysis\", \"technical analysis\": \"stock_analysis\",\n",
    "    \"fundamental analysis\": \"stock_analysis\", \"price target\": \"stock_analysis\",\n",
    "    \"valuation analysis\": \"stock_analysis\", \"stock forecast\": \"stock_analysis\",\n",
    "    \"long-term outlook\": \"stock_analysis\", \"stock trends\": \"stock_analysis\",\n",
    "    \"price action\": \"stock_analysis\", \"valuation metrics\": \"stock_analysis\",\n",
    "    \"investment potential\": \"stock_analysis\", \"shares\": \"stock_analysis\",\n",
    "    \"forecast\": \"stock_analysis\", \"price targets\": \"stock_analysis\",\n",
    "    \"performing\": \"stock_analysis\", \"stock valuation\": \"stock_analysis\",\n",
    "    \"comparative analysis\": \"stock_analysis\", # Can be broad, but often applied to stocks\n",
    "    \"fundamentals\": \"stock_analysis\",\n",
    "\n",
    "    # --- Quarterly Report Summary ---\n",
    "    \"financial report\": \"quarterly_report_summary\", \"q report\": \"quarterly_report_summary\",\n",
    "    \"quarterly earnings\": \"quarterly_report_summary\", \"earnings summary\": \"quarterly_report_summary\",\n",
    "    \"fiscal results\": \"quarterly_report_summary\", \"latest financials\": \"quarterly_report_summary\",\n",
    "    \"income statement\": \"quarterly_report_summary\", \"balance sheet\": \"quarterly_report_summary\",\n",
    "    \"cash flow statement\": \"quarterly_report_summary\", \"earnings call\": \"quarterly_report_summary\",\n",
    "    \"10-q report\": \"quarterly_report_summary\", \"10-k report\": \"quarterly_report_summary\",\n",
    "    \"financial results\": \"quarterly_report_summary\", \"profit and loss\": \"quarterly_report_summary\",\n",
    "    \"financial highlights\": \"quarterly_report_summary\", \"beat estimates\": \"quarterly_report_summary\",\n",
    "    \"earnings call summary\": \"quarterly_report_summary\", \"revenue and profit\": \"quarterly_report_summary\",\n",
    "    \"earnings per share\": \"quarterly_report_summary\", \"recent report\": \"quarterly_report_summary\",\n",
    "    \"balance sheet summary\": \"quarterly_report_summary\", \"operating margins\": \"quarterly_report_summary\",\n",
    "\n",
    "    # --- Fixed Income Analysis ---\n",
    "    \"bond analysis\": \"fixed_income_analysis\", \"analyze bond\": \"fixed_income_analysis\",\n",
    "    \"fixed income\": \"fixed_income_analysis\", \"bond details\": \"fixed_income_analysis\",\n",
    "    \"credit rating\": \"fixed_income_analysis\", \"bond yield\": \"fixed_income_analysis\",\n",
    "    \"debt security\": \"fixed_income_analysis\", \"corporate bond\": \"fixed_income_analysis\",\n",
    "    \"treasury yield\": \"fixed_income_analysis\", \"credit risk\": \"fixed_income_analysis\",\n",
    "    \"yield curve\": \"fixed_income_analysis\", \"bond duration\": \"fixed_income_analysis\",\n",
    "    \"current rates\": \"fixed_income_analysis\", \"municipal bonds\": \"fixed_income_analysis\",\n",
    "    \"default probabilities\": \"fixed_income_analysis\", \"duration and convexity\": \"fixed_income_analysis\",\n",
    "    \"credit risk assessment\": \"fixed_income_analysis\", \"yield analysis\": \"fixed_income_analysis\",\n",
    "    \"spreads\": \"fixed_income_analysis\", \"floating rate notes\": \"fixed_income_analysis\",\n",
    "    \"debt instrument analysis\": \"fixed_income_analysis\", \"zero-coupon bonds\": \"fixed_income_analysis\",\n",
    "    \"investment grade debt\": \"fixed_income_analysis\", \"commercial paper\": \"fixed_income_analysis\",\n",
    "\n",
    "    # --- Sector Analysis ---\n",
    "    \"sector performance\": \"sector_analysis\", \"industry comparison\": \"sector_analysis\",\n",
    "    \"sector analysis\": \"sector_analysis\", \"industry outlook\": \"sector_analysis\",\n",
    "    \"market segment\": \"sector_analysis\", \"sector trends\": \"sector_analysis\",\n",
    "    \"regulatory impact\": \"sector_analysis\", \"profitability metrics\": \"sector_analysis\",\n",
    "    \"competitive landscape\": \"sector_analysis\", \"supply chain dynamics\": \"sector_analysis\",\n",
    "    \"emerging trends\": \"sector_analysis\", \"growth projections\": \"sector_analysis\",\n",
    "    \"top performers\": \"sector_analysis\", \"industry analysis\": \"sector_analysis\",\n",
    "    \"real estate sector\": \"sector_analysis\", \"communication services sector\": \"sector_analysis\",\n",
    "    \"healthcare sector\": \"sector_analysis\", \"financial sector\": \"sector_analysis\",\n",
    "    \"industrials sector\": \"sector_analysis\", \"energy sector\": \"sector_analysis\",\n",
    "    \"materials sector\": \"sector_analysis\", \"utilities sector\": \"sector_analysis\"\n",
    "}\n",
    "\n",
    "def get_current_quarter_year():\n",
    "    \"\"\"Returns the current quarter and year in QX-YYYY format.\"\"\"\n",
    "    now = datetime.now()\n",
    "    quarter = (now.month - 1) // 3 + 1\n",
    "    return f\"Q{quarter}-{now.year}\"\n",
    "\n",
    "@traceable(run_type=\"tool\") # Mark for LangSmith tracing\n",
    "def get_ticker_from_name(company_name: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Attempts to find a stock ticker for a given company name,\n",
    "    first checking a local cache, then using the FMP API.\n",
    "    \"\"\"\n",
    "    normalized_name = company_name.lower().strip()\n",
    "\n",
    "    # 1. Check local ENTITY_MAPPINGS cache\n",
    "    if normalized_name in ENTITY_MAPPINGS:\n",
    "        print(f\"[Ticker Lookup] Cache hit for '{company_name}': {ENTITY_MAPPINGS[normalized_name]}\")\n",
    "        return ENTITY_MAPPINGS[normalized_name]\n",
    "    \n",
    "    # 2. If not in cache, try FMP API\n",
    "    fmp_api_key = os.getenv(\"FMP_API_KEY\")\n",
    "    if not fmp_api_key:\n",
    "        print(\"[Ticker Lookup] FMP_API_KEY is not set. Skipping API lookup.\")\n",
    "        return None\n",
    "\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/search?query={normalized_name}&limit=1&exchange=NASDAQ&apikey={fmp_api_key}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "        data = response.json()\n",
    "\n",
    "        if data and len(data) > 0:\n",
    "            ticker = data[0].get('symbol')\n",
    "            if ticker:\n",
    "                ENTITY_MAPPINGS[normalized_name] = ticker # Add to cache\n",
    "                print(f\"[Ticker Lookup] FMP API found '{company_name}' -> {ticker}. Added to cache.\")\n",
    "                return ticker\n",
    "            else:\n",
    "                print(f\"[Ticker Lookup] FMP API found data but no symbol for '{company_name}'.\")\n",
    "        else:\n",
    "            print(f\"[Ticker Lookup] No results from FMP API for '{company_name}'.\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"[Ticker Lookup] FMP API request timed out for '{company_name}'.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[Ticker Lookup] Error calling FMP API for '{company_name}': {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"Domain knowledge base and rules defined.\")\n",
    "print(\"Dynamic ticker lookup (FMP API) function enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77848690-d614-4c1e-b5c9-fb43de631437",
   "metadata": {},
   "source": [
    "\n",
    "### Phase 2: Crafting the Financial Intelligence: Prompt Optimizer Logic & LLM Simulation Pipeline\n",
    "\n",
    "**What it is:**\n",
    "This is the \"brain\" of our system. It contains the core logic that transforms a user's messy, natural language request into a precise, structured, and compliant prompt that our LLM can understand and act upon. It also sets up the sequential flow (pipeline) using LangChain.\n",
    "\n",
    "**Why it's needed:**\n",
    "*   **Bridge the Gap:** LLMs are powerful but often need specific instructions. This phase translates vague human intent into crystal-clear AI commands.\n",
    "*   **Enforce Compliance & Structure:** It injects the regulatory rules and desired output formats directly into the prompt, ensuring the LLM's response meets strict financial requirements.\n",
    "*   **Orchestration:** LangChain allows us to build a series of steps (optimizer -> LLM) that execute in order, making the workflow transparent and manageable.\n",
    "\n",
    "**How it works (Code Meaning):**\n",
    "\n",
    "1.  **`financial_prompt_optimizer(original_prompt: str)`:** This is our custom \"optimizer\" function.\n",
    "    *   `@traceable(run_type=\"tool\")`: Again, LangSmith tracks this entire function's execution.\n",
    "    *   **Input & Normalization:** Takes the `original_prompt` (e.g., \"Analyze Apple stock\") and converts it to `lower_prompt` for case-insensitive matching.\n",
    "    *   **1. Entity Extraction:**\n",
    "        *   It first tries to find company names from `ENTITY_MAPPINGS` within the `lower_prompt`.\n",
    "        *   It then uses a regular expression (`re.search(r'\\b[A-Z]{2,5}\\b'`) to find potential stock tickers directly (e.g., \"TSLA\").\n",
    "        *   **Crucially, it then uses a heuristic to try to identify other capitalized words in the prompt that might be company names (e.g., \"Microsoft\") and calls `get_ticker_from_name()` (from Phase 1) to dynamically look them up via FMP.** This significantly improves its ability to handle companies not in the initial cache.\n",
    "    *   **Timeframe Extraction:** Uses regular expressions to find various date/time mentions (`Q1-2023`, `2024`, `YTD`, `last quarter`, `this year`, `last year`). It calculates the actual quarter/year for relative terms.\n",
    "    *   **2. Intent Recognition & Rule Application:**\n",
    "        *   It iterates through the `INTENT_MAPPINGS` dictionary. If any `keyword` (e.g., \"quarterly earnings\") is found as a substring in the `lower_prompt`, the corresponding `identified_intent` (e.g., \"quarterly_report_summary\") is set. **The order of keywords in `INTENT_MAPPINGS` can matter here, as it stops at the first match.**\n",
    "        *   **Fallback:** If no explicit intent keyword is found *but a ticker was extracted*, it defaults to `stock_analysis` (a common user pattern).\n",
    "        *   **Error Handling:** If no clear intent is found, it returns a user-friendly error message, guiding them to be more specific.\n",
    "        *   Once the `identified_intent` is determined, it fetches the corresponding `rules` (rule name, tasks, output format) from the `COMPLIANCE_RULES` dictionary.\n",
    "    *   **3. Construct the Optimized Prompt:**\n",
    "        *   This is the core \"prompt engineering\" step. It uses an f-string to build a highly specific and structured prompt for the LLM.\n",
    "        *   It includes a persona (\"You are a highly specialized financial AI assistant\").\n",
    "        *   It injects the `rule_name`, extracted `ticker` (or a placeholder), extracted `timeframe`, the specific `tasks` (from `tasks_template`), and the precise `output_format_spec` into the prompt.\n",
    "        *   This ensures the LLM receives clear instructions on *what* to do, *for whom*, *when*, and *in what exact format*.\n",
    "    *   Returns the `optimized_prompt` string.\n",
    "\n",
    "2.  **`mock_financial_llm(optimized_prompt: str)`:** This function simulates the behavior of a real financial LLM.\n",
    "    *   `@traceable(run_type=\"llm\")`: LangSmith will track this as an \"LLM call.\"\n",
    "    *   **Purpose:** Since a real financial LLM is complex and costly to run repeatedly during development, this mock function acts as a stand-in.\n",
    "    *   **Behavior:** It inspects the `optimized_prompt` to identify the `rule_name` (e.g., \"SEC Rule 13f\"). Based on this, it returns a **hardcoded JSON string** that mimics the *expected structure and type of data* a real LLM would produce for that rule, including simulated narratives.\n",
    "    *   This is crucial for testing that your `financial_prompt_optimizer` is generating the correct prompts and that your downstream parsing/visualization logic can handle the expected output formats.\n",
    "\n",
    "3.  **`financial_analysis_chain` (LangChain Pipeline):**\n",
    "    *   This is where we define the execution flow:\n",
    "        *   `RunnableLambda(financial_prompt_optimizer)`: The user's input first goes to our `financial_prompt_optimizer`.\n",
    "        *   `|`: This is LangChain's \"pipe\" operator, meaning the output of the left side becomes the input of the right side.\n",
    "        *   `RunnableLambda(mock_financial_llm)`: The optimized prompt from the optimizer is then passed to our `mock_financial_llm`.\n",
    "    *   This chain defines the entire logical sequence for processing a user's request. We explicitly chose the `mock_financial_llm` here to avoid API costs and focus on testing the optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a538c0f7-b1d3-4743-ae36-ed8a7c298ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Designing & Building the Optimizer and LLM Simulation ---\n",
      "Prompt optimization engine defined.\n",
      "Mock LLM defined for testing and active in the chain.\n",
      "\n",
      "Configuring LangChain pipeline...\n",
      "LangChain pipeline configured.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Phase 2: Designing & Building the Optimizer and LLM Simulation ---\")\n",
    "\n",
    "# 2.1. Model Selection (Our \"Optimizer Model\" and LLM Simulation)\n",
    "# Our \"model\" for prompt optimization is a rule-based Python function.\n",
    "# We will use the mock LLM for testing.\n",
    "\n",
    "# 2.2. Prompt Engineering & Fine-Tuning (for the Optimizer)\n",
    "@traceable(run_type=\"tool\") # Mark this function for LangSmith tracing\n",
    "def financial_prompt_optimizer(original_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes an original user prompt and transforms it into an optimized,\n",
    "    compliance-aware, and structured prompt for a financial LLM.\n",
    "    \"\"\"\n",
    "    print(f\"\\n[Optimizer] Original Input: '{original_prompt}'\")\n",
    "\n",
    "    # Initialize extracted entities\n",
    "    ticker = None\n",
    "    timeframe = None\n",
    "    \n",
    "    lower_prompt = original_prompt.lower()\n",
    "\n",
    "    # 1. Entity Extraction\n",
    "    # Try to extract ticker directly from ENTITY_MAPPINGS (our cache)\n",
    "    for company_name, stock_ticker in ENTITY_MAPPINGS.items():\n",
    "        if company_name in lower_prompt:\n",
    "            ticker = stock_ticker\n",
    "            break\n",
    "    \n",
    "    # Also look for direct ticker patterns (e.g., \"TSLA\", \"$AAPL\") if not found by company name\n",
    "    if not ticker:\n",
    "        ticker_match = re.search(r'\\b[A-Z]{2,5}\\b', original_prompt)\n",
    "        if ticker_match:\n",
    "            potential_ticker = ticker_match.group().upper()\n",
    "            # If the directly matched ticker is in our known values, use it.\n",
    "            # Else, consider it not found by direct ticker pattern for this simplified flow.\n",
    "            if potential_ticker in ENTITY_MAPPINGS.values():\n",
    "                ticker = potential_ticker\n",
    "\n",
    "    # If ticker still not found after checking cache or direct ticker match,\n",
    "    # try dynamic lookup by iterating words in the prompt that might be company names.\n",
    "    if not ticker:\n",
    "        words = original_prompt.split()\n",
    "        for word in words:\n",
    "            # Simple heuristic: try to find capitalized words (potential proper nouns)\n",
    "            # and attempt dynamic lookup if not a common small word.\n",
    "            if word.istitle() and len(word) > 1 and word.lower() not in [\"the\", \"a\", \"an\", \"is\", \"of\", \"for\", \"in\", \"and\", \"or\", \"how\", \"what\", \"that\", \"which\", \"this\", \"these\", \"those\", \"my\", \"your\", \"our\", \"its\", \"their\", \"his\", \"her\", \"they\", \"we\", \"you\", \"it\"]:\n",
    "                found_ticker = get_ticker_from_name(word.strip(\".,!?\"))\n",
    "                if found_ticker:\n",
    "                    ticker = found_ticker\n",
    "                    break\n",
    "\n",
    "    # Extract Timeframe (e.g., Q1-2023, 2024, YTD, last quarter, current quarter, this year, last year)\n",
    "    timeframe_match = re.search(r'(Q[1-4]-\\d{4}|\\b\\d{4}\\b|\\bYTD\\b|\\blast quarter\\b|\\bcurrent quarter\\b|\\bthis year\\b|\\blast year\\b)', original_prompt, re.IGNORECASE)\n",
    "    if timeframe_match:\n",
    "        extracted_timeframe = timeframe_match.group().lower()\n",
    "        now = datetime.now()\n",
    "        if \"last quarter\" in extracted_timeframe:\n",
    "            if now.month <= 3: prev_quarter_num, prev_quarter_year = 4, now.year - 1\n",
    "            elif now.month <= 6: prev_quarter_num, prev_quarter_year = 1, now.year\n",
    "            elif now.month <= 9: prev_quarter_num, prev_quarter_year = 2, now.year\n",
    "            else: prev_quarter_num, prev_quarter_year = 3, now.year\n",
    "            timeframe = f\"Q{prev_quarter_num}-{prev_quarter_year}\"\n",
    "        elif \"current quarter\" in extracted_timeframe:\n",
    "            timeframe = get_current_quarter_year()\n",
    "        elif \"last year\" in extracted_timeframe:\n",
    "            timeframe = str(now.year - 1)\n",
    "        elif \"this year\" in extracted_timeframe:\n",
    "            timeframe = str(now.year)\n",
    "        else:\n",
    "            timeframe = extracted_timeframe.upper() # Ensure QX-YYYY or YYYY is uppercase\n",
    "    else:\n",
    "        timeframe = get_current_quarter_year() # Default to current quarter if not specified\n",
    "\n",
    "    print(f\"[Optimizer] Extracted: Ticker={ticker if ticker else 'N/A'}, Timeframe={timeframe}\")\n",
    "\n",
    "    # 2. Intent Recognition & Rule Application\n",
    "    identified_intent = None\n",
    "    # Iterate through keywords to find intent. Order matters: More specific phrases first is generally better.\n",
    "    # The current order in INTENT_MAPPINGS tries to group by intent type.\n",
    "    for keyword, intent_type in INTENT_MAPPINGS.items():\n",
    "        if keyword in lower_prompt:\n",
    "            identified_intent = intent_type\n",
    "            break\n",
    "    \n",
    "    # Default intent if a ticker is present but no specific intent found\n",
    "    if not identified_intent and ticker:\n",
    "        identified_intent = \"stock_analysis\"\n",
    "    \n",
    "    # Handle cases where no clear intent can be determined\n",
    "    if not identified_intent:\n",
    "        error_msg = f\"Error: Could not determine clear intent for '{original_prompt}'. Please specify the financial task (e.g., 'stock analysis', 'quarterly report summary', 'bond analysis', 'sector analysis').\"\n",
    "        print(f\"[Optimizer] {error_msg}\")\n",
    "        return error_msg # Return error message instead of an optimized prompt\n",
    "\n",
    "    rules = COMPLIANCE_RULES.get(identified_intent)\n",
    "    if not rules:\n",
    "        error_msg = f\"Error: No compliance rules defined for inferred intent '{identified_intent}'. Please refine intent mapping or rules.\"\n",
    "        print(f\"[Optimizer] {error_msg}\")\n",
    "        return error_msg # Return error message\n",
    "\n",
    "    rule_name = rules[\"rule_name\"]\n",
    "    tasks = \"\\n\".join(rules[\"tasks_template\"])\n",
    "    output_format_spec = rules[\"output_format_spec\"]\n",
    "\n",
    "    # 3. Construct the Optimized Prompt\n",
    "    optimized_prompt = f\"\"\"\n",
    "You are a highly specialized financial AI assistant. Perform the requested analysis following all specified rules and output formats.\n",
    "\n",
    "Perform {rule_name}-compliant analysis of {ticker if ticker else 'the specified entity'} for {timeframe}:\n",
    "{tasks}\n",
    "\n",
    "Output: {output_format_spec}\n",
    "\"\"\"\n",
    "    optimized_prompt = optimized_prompt.strip() # Clean up leading/trailing whitespace\n",
    "\n",
    "    print(f\"[Optimizer] Optimized Prompt Generated:\\n---\\n{optimized_prompt}\\n---\")\n",
    "    return optimized_prompt\n",
    "\n",
    "print(\"Prompt optimization engine defined.\")\n",
    "\n",
    "# 2.3. Prototype Development: Simulate LLM Interaction with LangChain and LangSmith\n",
    "\n",
    "# Option A: Mock LLM (This is NOW ACTIVE)\n",
    "@traceable(run_type=\"llm\") # Mark this function for LangSmith tracing\n",
    "def mock_financial_llm(optimized_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    A mock LLM that simulates a financial analysis response based on the optimized prompt.\n",
    "    It returns a generic JSON structure as specified.\n",
    "    \"\"\"\n",
    "    print(f\"\\n[Mock LLM] Receiving Input:\\n---\\n{optimized_prompt}\\n---\")\n",
    "\n",
    "    mock_response_data = {\n",
    "        \"status\": \"mock_analysis_completed\",\n",
    "        \"notes\": \"This is a simulated LLM response based on the optimized prompt.\",\n",
    "        \"compliance_checked\": True\n",
    "    }\n",
    "\n",
    "    # Craft a more specific mock response based on the identified rule\n",
    "    if \"SEC Rule 13f\" in optimized_prompt:\n",
    "        mock_response_data.update({\n",
    "            \"metrics\": [\n",
    "                {\"volatility_5yr\": \"2.8%\"},\n",
    "                {\"beta\": \"1.35\"},\n",
    "                {\"institutional_ownership_change_QoQ\": \"+2.1%\"}\n",
    "            ],\n",
    "            \"risk_assessment\": {\n",
    "                \"ESG_exposure\": \"Moderate (Carbon Emissions, Supply Chain)\",\n",
    "                \"regulatory_risk\": \"Low\"\n",
    "            },\n",
    "            \"compliance_check\": True,\n",
    "            \"narrative\": \"Mock analysis following SEC Rule 13f guidelines for stock analysis. This is a simulated narrative demonstrating human-like text.\"\n",
    "        })\n",
    "    elif \"GAAP Principles\" in optimized_prompt:\n",
    "         mock_response_data.update({\n",
    "            \"summary\": {\n",
    "                \"revenue_QoQ\": \"+7.2%\",\n",
    "                \"net_income_YoY\": \"+12.5%\",\n",
    "                \"EPS\": \"1.52\"\n",
    "            },\n",
    "            \"financials\": {\n",
    "                \"assets\": \"120M USD\",\n",
    "                \"liabilities\": \"60M USD\",\n",
    "                \"equity\": \"60M USD\"\n",
    "            },\n",
    "            \"cash_flow\": {\n",
    "                \"operating\": \"20M USD\",\n",
    "                \"investing\": \"-5M USD\"\n",
    "            },\n",
    "            \"narrative\": \"Mock quarterly report summary adhering to GAAP principles, highlighting key financial trends and a simulated outlook, designed for readability.\",\n",
    "            \"compliance_check\": True\n",
    "        })\n",
    "    elif \"FINRA Rule 2210\" in optimized_prompt:\n",
    "        mock_response_data.update({\n",
    "            \"bond_details\": {\n",
    "                \"issuer\": \"Corp Bond A\",\n",
    "                \"credit_rating_sp\": \"AA+\",\n",
    "                \"current_yield\": \"4.2%\",\n",
    "                \"ytm\": \"4.55%\"\n",
    "            },\n",
    "            \"risk_factors\": {\n",
    "                \"call_provision\": \"Yes (after 5 years)\",\n",
    "                \"covenants_summary\": \"Standard financial covenants apply\"\n",
    "            },\n",
    "            \"compliance_notes\": \"Mock bond communication analysis per FINRA Rule 2210, ensuring balanced presentation.\",\n",
    "            \"overall_assessment\": \"This is a simulated overall assessment of the bond's characteristics, providing a human-like summary.\"\n",
    "        })\n",
    "    elif \"SEC Regulation Fair Disclosure\" in optimized_prompt:\n",
    "        mock_response_data.update({\n",
    "            \"sector_metrics\": [\n",
    "                {\"performance_vs_market\": \"+3.5%\"},\n",
    "                {\"q_q_growth\": \"+5.1%\"},\n",
    "                {\"leading_companies\": [\"Company A\", \"Company B\"]}\n",
    "            ],\n",
    "            \"top_performers\": [\"Specific Company 1\", \"Specific Company 2\"],\n",
    "            \"risk_factors\": {\n",
    "                \"regulatory_changes\": \"Moderate\",\n",
    "                \"supply_chain_disruptions\": \"Low\"\n",
    "            },\n",
    "            \"compliance_checked\": True,\n",
    "            \"commentary\": \"Mock sector analysis adhering to SEC Reg FD, providing key insights and a simulated market commentary on emerging trends and outlook.\"\n",
    "        })\n",
    "    \n",
    "    mock_json_output = json.dumps(mock_response_data, indent=2)\n",
    "    print(f\"[Mock LLM] Responding with (truncated):\\n---\\n{mock_json_output[:200]}...\\n---\") # Truncate for display\n",
    "    return mock_json_output\n",
    "\n",
    "print(\"Mock LLM defined for testing and active in the chain.\")\n",
    "\n",
    "# Option B: Real LLM (e.g., OpenAI's GPT) - This block is explicitly commented out as requested.\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# real_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# print(\"Real LLM (OpenAI) initialized (but bypassed in the chain).\")\n",
    "\n",
    "\n",
    "# Construct the LangChain Pipeline\n",
    "print(\"\\nConfiguring LangChain pipeline...\")\n",
    "\n",
    "financial_analysis_chain = (\n",
    "    RunnableLambda(financial_prompt_optimizer) | # Step 1: Optimize the prompt\n",
    "    RunnableLambda(mock_financial_llm)           # <--- Step 2: MOCK LLM (ACTIVE)\n",
    ")\n",
    "\n",
    "print(\"LangChain pipeline configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9704d-ad3a-474a-9a64-d57c3070f18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb44e-4130-436f-92d6-991b4af0d9a3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Phase 3: Interactive Testing and Evaluation\n",
    "\n",
    "**What it is:**\n",
    "This is the interactive part of the Jupyter Notebook. It allows you to enter natural language financial requests and see the system's output in real-time. It also initiates the crucial traceability in LangSmith.\n",
    "\n",
    "**Why it's needed:**\n",
    "*   **Rapid Iteration:** Allows developers to quickly test different user queries and see how the optimizer and LLM respond.\n",
    "*   **Debugging:** Immediate feedback helps identify issues in prompt optimization, entity extraction, or intent recognition.\n",
    "*   **Observability in LangSmith:** Every query run in this phase automatically generates a detailed \"trace\" in your LangSmith dashboard, providing an unparalleled audit trail and debugging tool.\n",
    "*   **Human-Friendly Output:** This phase also includes code to take the structured JSON and present it in a more readable format (tables, narratives).\n",
    "\n",
    "**How it works (Code Meaning):**\n",
    "\n",
    "1.  **`while True: ... input(...)`:** This creates an infinite loop that constantly prompts you to `Enter your request: `. You type your query, press Enter, and the system processes it. Typing `exit` breaks the loop.\n",
    "2.  **`financial_analysis_chain.invoke(user_input)`:** This is the magic line! It takes your typed `user_input` and starts the LangChain pipeline defined in Phase 2. Because `LANGCHAIN_TRACING_V2` is enabled, LangSmith automatically starts a new trace for this invocation.\n",
    "3.  **JSON Parsing & Display:**\n",
    "    *   `json.loads(final_output)`: Attempts to convert the LLM's (mock) JSON output string into a Python dictionary.\n",
    "    *   `json.dumps(parsed_output, indent=2)`: Pretty-prints the JSON dictionary to the console, making it easy to read.\n",
    "    *   `except json.JSONDecodeError`: Catches cases where the output isn't valid JSON (e.g., if the optimizer returned an error message like \"Error: Could not determine clear intent...\"). In such cases, it just prints the raw output.\n",
    "4.  **Enhanced Basic Visualization Logic:**\n",
    "    *   `if parsed_output:`: This block activates only if the LLM output was valid JSON.\n",
    "    *   `if \"metrics\" in parsed_output ... elif \"summary\" in parsed_output ...`: These `if/elif` statements check for specific keys within the returned JSON to identify the type of analysis (stock, quarterly, fixed income, sector).\n",
    "    *   `import pandas as pd`: Pandas DataFrames are used to format numerical or tabular data (like metrics, financials, bond details) into clean, readable tables directly in the Jupyter output.\n",
    "    *   `print(df.to_string(index=False))`: Prints the DataFrame without the usual row index, for a cleaner look.\n",
    "    *   `if \"narrative\" in parsed_output ...`: These separate checks specifically look for and print the human-like narrative/commentary fields (`narrative`, `analysis_details`, `overall_assessment`, `commentary`) that were requested in the `COMPLIANCE_RULES` `output_format_spec`. This fulfills the \"human-like\" output requirement.\n",
    "5.  **`except Exception as e:`:** A general error handler to catch any unexpected issues during the process, providing feedback.\n",
    "6.  **LangSmith Call to Action:** At the end, it reminds you to visit `smith.langchain.com` to see the detailed traces, which is crucial for understanding how each query was processed step-by-step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de1ad2a6-2ecf-42e2-bd51-455af1567d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 3: Interactive Testing and Evaluation ---\n",
      "Enter your financial analysis requests below. Type 'exit' to quit.\n",
      "Each request will generate a trace in LangSmith (smith.langchain.com).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your request:  Growth projections for healthcare sector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[System] Processing request...\n",
      "\n",
      "[Optimizer] Original Input: 'Growth projections for healthcare sector'\n",
      "[Ticker Lookup] FMP API found 'Growth' -> GCACW. Added to cache.\n",
      "[Optimizer] Extracted: Ticker=GCACW, Timeframe=Q3-2025\n",
      "[Optimizer] Optimized Prompt Generated:\n",
      "---\n",
      "You are a highly specialized financial AI assistant. Perform the requested analysis following all specified rules and output formats.\n",
      "\n",
      "Perform SEC Regulation Fair Disclosure-compliant analysis of GCACW for Q3-2025:\n",
      "(a) Sector performance vs. broader market\n",
      "(b) Key growth drivers in the sector\n",
      "(c) Regulatory risk factors\n",
      "(d) Market commentary and future outlook.\n",
      "\n",
      "Output: JSON with {sector_metrics: [], top_performers: [], risk_factors: {}, commentary: string}\n",
      "---\n",
      "\n",
      "[Mock LLM] Receiving Input:\n",
      "---\n",
      "You are a highly specialized financial AI assistant. Perform the requested analysis following all specified rules and output formats.\n",
      "\n",
      "Perform SEC Regulation Fair Disclosure-compliant analysis of GCACW for Q3-2025:\n",
      "(a) Sector performance vs. broader market\n",
      "(b) Key growth drivers in the sector\n",
      "(c) Regulatory risk factors\n",
      "(d) Market commentary and future outlook.\n",
      "\n",
      "Output: JSON with {sector_metrics: [], top_performers: [], risk_factors: {}, commentary: string}\n",
      "---\n",
      "[Mock LLM] Responding with (truncated):\n",
      "---\n",
      "{\n",
      "  \"status\": \"mock_analysis_completed\",\n",
      "  \"notes\": \"This is a simulated LLM response based on the optimized prompt.\",\n",
      "  \"compliance_checked\": true,\n",
      "  \"sector_metrics\": [\n",
      "    {\n",
      "      \"performance_vs_m...\n",
      "---\n",
      "\n",
      "--- Final LLM (Mock) Output ---\n",
      "{\n",
      "  \"status\": \"mock_analysis_completed\",\n",
      "  \"notes\": \"This is a simulated LLM response based on the optimized prompt.\",\n",
      "  \"compliance_checked\": true,\n",
      "  \"sector_metrics\": [\n",
      "    {\n",
      "      \"performance_vs_market\": \"+3.5%\"\n",
      "    },\n",
      "    {\n",
      "      \"q_q_growth\": \"+5.1%\"\n",
      "    },\n",
      "    {\n",
      "      \"leading_companies\": [\n",
      "        \"Company A\",\n",
      "        \"Company B\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"top_performers\": [\n",
      "    \"Specific Company 1\",\n",
      "    \"Specific Company 2\"\n",
      "  ],\n",
      "  \"risk_factors\": {\n",
      "    \"regulatory_changes\": \"Moderate\",\n",
      "    \"supply_chain_disruptions\": \"Low\"\n",
      "  },\n",
      "  \"commentary\": \"Mock sector analysis adhering to SEC Reg FD, providing key insights and a simulated market commentary on emerging trends and outlook.\"\n",
      "}\n",
      "\n",
      "--- Generating Basic Visualization ---\n",
      "\n",
      "--- Sector Metrics ---\n",
      "performance_vs_market q_q_growth      leading_companies\n",
      "                +3.5%      +5.1% [Company A, Company B]\n",
      "\n",
      "--- Top Performers ---\n",
      "Specific Company 1, Specific Company 2\n",
      "\n",
      "--- Risk Factors ---\n",
      "- Regulatory Changes: Moderate\n",
      "- Supply Chain Disruptions: Low\n",
      "Compliance Check: True\n",
      "\n",
      "--- Market Commentary ---\n",
      "Mock sector analysis adhering to SEC Reg FD, providing key insights and a simulated market commentary on emerging trends and outlook.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your request:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Session Ended ---\n",
      "Now, go to LangSmith (smith.langchain.com) to review the traces under the 'FinancialPromptOptimizer' project.\n",
      "Look for the 'tool' (our optimizer) and 'llm' (our mock/real LLM) runs within each trace.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Phase 3: Interactive Testing and Evaluation ---\")\n",
    "print(\"Enter your financial analysis requests below. Type 'exit' to quit.\")\n",
    "print(\"Each request will generate a trace in LangSmith (smith.langchain.com).\")\n",
    "\n",
    "# pandas is imported in Phase 1 now, but including here for self-containment if running just this cell\n",
    "# import pandas as pd \n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter your request: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        print(\"\\n[System] Processing request...\")\n",
    "        final_output = financial_analysis_chain.invoke(user_input)\n",
    "        \n",
    "        print(\"\\n--- Final LLM (Mock) Output ---\")\n",
    "        \n",
    "        parsed_output = None\n",
    "        try:\n",
    "            parsed_output = json.loads(final_output)\n",
    "            print(json.dumps(parsed_output, indent=2))\n",
    "        except json.JSONDecodeError:\n",
    "            print(final_output)\n",
    "            print(\"\\n[Visualization] Skipping visualization: Output is not valid JSON.\")\n",
    "            continue\n",
    "            \n",
    "        # --- Basic Visualization Logic (Enhanced) ---\n",
    "        print(\"\\n--- Generating Basic Visualization ---\")\n",
    "        \n",
    "        if parsed_output:\n",
    "            # Example 1: Stock Analysis Visualization\n",
    "            if \"metrics\" in parsed_output and isinstance(parsed_output[\"metrics\"], list):\n",
    "                print(\"\\n--- Stock Metrics ---\")\n",
    "                flat_metrics = {}\n",
    "                for item in parsed_output[\"metrics\"]:\n",
    "                    flat_metrics.update(item)\n",
    "                df_metrics = pd.DataFrame([flat_metrics])\n",
    "                print(df_metrics.to_string(index=False))\n",
    "                \n",
    "                print(\"\\n--- Risk Assessment ---\")\n",
    "                if \"risk_assessment\" in parsed_output:\n",
    "                    for k, v in parsed_output[\"risk_assessment\"].items():\n",
    "                        print(f\"- {k.replace('_', ' ').title()}: {v}\")\n",
    "                print(f\"Compliance Check: {parsed_output.get('compliance_check', 'N/A')}\")\n",
    "\n",
    "            # Example 2: Quarterly Report Summary Visualization\n",
    "            elif \"summary\" in parsed_output and \"financials\" in parsed_output:\n",
    "                print(\"\\n--- Quarterly Report Summary ---\")\n",
    "                print(f\"Revenue QoQ: {parsed_output['summary'].get('revenue_QoQ', 'N/A')}\")\n",
    "                print(f\"Net Income YoY: {parsed_output['summary'].get('net_income_YoY', 'N/A')}\")\n",
    "                print(f\"EPS: {parsed_output['summary'].get('EPS', 'N/A')}\")\n",
    "\n",
    "                print(\"\\n--- Key Financials ---\")\n",
    "                financial_df = pd.DataFrame([parsed_output[\"financials\"]])\n",
    "                print(financial_df.to_string(index=False))\n",
    "\n",
    "                print(\"\\n--- Cash Flow Analysis ---\")\n",
    "                cash_flow_df = pd.DataFrame([parsed_output[\"cash_flow\"]])\n",
    "                print(cash_flow_df.to_string(index=False))\n",
    "                \n",
    "                print(f\"\\nCompliance Check: {parsed_output.get('compliance_check', 'N/A')}\")\n",
    "            \n",
    "            # Example 3: Fixed Income Analysis Visualization\n",
    "            elif \"bond_details\" in parsed_output and \"risk_factors\" in parsed_output:\n",
    "                print(\"\\n--- Bond Details ---\")\n",
    "                bond_details_df = pd.DataFrame([parsed_output[\"bond_details\"]])\n",
    "                print(bond_details_df.to_string(index=False))\n",
    "\n",
    "                print(\"\\n--- Risk Factors ---\")\n",
    "                if \"risk_factors\" in parsed_output:\n",
    "                    for k, v in parsed_output[\"risk_factors\"].items():\n",
    "                        print(f\"- {k.replace('_', ' ').title()}: {v}\")\n",
    "                print(f\"Compliance Notes: {parsed_output.get('compliance_notes', 'N/A')}\")\n",
    "\n",
    "            # Example 4: Sector Analysis Visualization\n",
    "            elif \"sector_metrics\" in parsed_output and isinstance(parsed_output[\"sector_metrics\"], list):\n",
    "                print(\"\\n--- Sector Metrics ---\")\n",
    "                flat_sector_metrics = {}\n",
    "                for item in parsed_output[\"sector_metrics\"]:\n",
    "                    flat_sector_metrics.update(item)\n",
    "                df_sector_metrics = pd.DataFrame([flat_sector_metrics])\n",
    "                print(df_sector_metrics.to_string(index=False))\n",
    "\n",
    "                print(\"\\n--- Top Performers ---\")\n",
    "                if \"top_performers\" in parsed_output and parsed_output[\"top_performers\"]:\n",
    "                    print(\", \".join(parsed_output[\"top_performers\"]))\n",
    "\n",
    "                print(\"\\n--- Risk Factors ---\")\n",
    "                if \"risk_factors\" in parsed_output:\n",
    "                    for k, v in parsed_output[\"risk_factors\"].items():\n",
    "                        print(f\"- {k.replace('_', ' ').title()}: {v}\")\n",
    "                print(f\"Compliance Check: {parsed_output.get('compliance_checked', 'N/A')}\")\n",
    "\n",
    "            # --- NEW: Always check for and print narrative/commentary fields ---\n",
    "            if \"narrative\" in parsed_output and parsed_output[\"narrative\"]:\n",
    "                print(f\"\\n--- Analysis Narrative ---\")\n",
    "                print(parsed_output[\"narrative\"])\n",
    "            elif \"analysis_details\" in parsed_output and parsed_output[\"analysis_details\"]:\n",
    "                print(f\"\\n--- Analysis Details ---\")\n",
    "                print(parsed_output[\"analysis_details\"])\n",
    "            elif \"overall_assessment\" in parsed_output and parsed_output[\"overall_assessment\"]:\n",
    "                print(f\"\\n--- Overall Assessment ---\")\n",
    "                print(parsed_output[\"overall_assessment\"])\n",
    "            elif \"commentary\" in parsed_output and parsed_output[\"commentary\"]:\n",
    "                print(f\"\\n--- Market Commentary ---\")\n",
    "                print(parsed_output[\"commentary\"])\n",
    "            \n",
    "            else:\n",
    "                print(\"[Visualization] No specific visualization logic found for this output structure or narrative fields.\")\n",
    "        else:\n",
    "            print(\"[Visualization] No parsed output available for visualization.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[System Error] An unexpected error occurred during processing or visualization: {e}\")\n",
    "        print(\"Please review the prompt optimization logic, your LLM configuration, or the new visualization code.\")\n",
    "\n",
    "print(\"\\n--- Testing Session Ended ---\")\n",
    "print(\"Now, go to LangSmith (smith.langchain.com) to review the traces under the 'FinancialPromptOptimizer' project.\")\n",
    "print(\"Look for the 'tool' (our optimizer) and 'llm' (our mock/real LLM) runs within each trace.\")\n",
    "\n",
    "# Example test prompts you can use:\n",
    "# 1. Analyze Tesla stock\n",
    "# 2. Give me a Q4-2023 financial report summary for Apple\n",
    "# 3. Analyze MSFT company performance 2022\n",
    "# 4. Perform stock analysis on Google for last quarter\n",
    "# 5. Analyze the bond issued by JP Morgan\n",
    "# 6. Summarize the quarterly earnings of Amazon\n",
    "# 7. What about fixed income analysis for a corporate bond?\n",
    "# 8. Analyze IBM\n",
    "# 9. Just give me some random info (to test error handling)\n",
    "# 10. Analyze the tech sector performance\n",
    "# 11. How is Netflix performing this year? (Tests new timeframe)\n",
    "# 12. Show me the 10-K report for Apple (Tests new report type)\n",
    "# 13. What are the recent financials for Adobe? (Tests new phrasing for quarterly)\n",
    "# 14. What's the credit risk on the KO bond? (Tests new bond phrasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6327cc3c-d50f-4bcc-9e91-e94b709e85d9",
   "metadata": {},
   "source": [
    "#### Q as a user i asked = Growth projections for healthcare sector\n",
    "\n",
    "**The provided output is a mock financial analysis for the healthcare sector, specifically for Q3-2025, adhering to SEC Regulation Fair Disclosure (Reg FD). It includes simulated sector performance metrics (e.g., +3.5% vs. broader market, +5.1% quarter-over-quarter growth), lists top-performing companies (Company A, Company B, Specific Company 1, Specific Company 2), highlights risk factors like \"Moderate\" regulatory changes and \"Low\" supply chain disruptions, and offers a market commentary on emerging trends and outlook, all as part of an interactive testing and evaluation phase.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68071f6a-1425-4ade-8d39-849739e45edd",
   "metadata": {},
   "source": [
    "### Phase 4: Deploy & Monitor (Conceptual)\n",
    "\n",
    "**What it is:**\n",
    "This phase shifts from hands-on coding to a conceptual discussion about taking this prototype to a real-world production environment. It emphasizes the importance of deployment strategies, user interfaces, and continuous monitoring.\n",
    "\n",
    "**Why it's needed:**\n",
    "*   **Real-World Application:** A Jupyter Notebook is for development. To provide a service to customers, the code needs to run reliably on a server.\n",
    "*   **Scalability & Maintainability:** Production systems require robust packaging, deployment, and operational oversight.\n",
    "*   **Continuous Improvement:** AI systems, especially those dealing with dynamic data and user language, need constant monitoring and updates.\n",
    "\n",
    "**How it works (Code Meaning / Explanation):**\n",
    "\n",
    "1.  **`4.1. Deployment Strategy (Conceptual):`**\n",
    "    *   Discusses packaging the code (Python module), containerization (Docker for consistency), and deploying as microservices (AWS Lambda, Google Cloud Run) with API endpoints. This explains how the \"brain\" you built would become an accessible service.\n",
    "2.  **`4.2. Application Integration (Conceptual Web Interface):`**\n",
    "    *   Outlines how a user-friendly web front-end (e.g., using Streamlit, a Python framework for simple web apps) would connect to your deployed backend. The pseudo-code shows how a user might type in a request and see the structured JSON output displayed beautifully. This addresses the \"what about the interface?\" question.\n",
    "3.  **`4.3. Monitoring & Maintenance (Crucial Role of LangSmith):`**\n",
    "    *   This section highlights **LangSmith's critical role in a production setting.**\n",
    "        *   **Automatic Logging & Audit Trail:** Every transaction is logged, providing a complete history for compliance and troubleshooting.\n",
    "        *   **Debugging & Performance:** You can track latency, success rates, and pinpoint exact issues by reviewing the inputs and outputs of each step in the pipeline.\n",
    "        *   **Drift Detection:** Monitoring user queries helps identify new trends or language that might require updates to your `INTENT_MAPPINGS` or `COMPLIANCE_RULES`.\n",
    "        *   **Feedback Loop:** Emphasizes collecting user feedback to further refine the AI's performance and prompt optimization logic.\n",
    "        *   **Periodic Updates:** Reinforces that financial systems require constant review due to changing regulations and market conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e3dfd2-e1dc-4927-9099-7e7602cf7fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PHASE 4: Deployment & Monitoring Considerations ---\n",
      "\n",
      "4.1. Deployment Strategy (Conceptual):\n",
      "Once the prompt optimization logic is robust and tested in Jupyter, for production deployment, you would typically:\n",
      "  - Package the `financial_prompt_optimizer` function and its dependencies into a Python module/library.\n",
      "  - Containerize the application (e.g., using Docker) to ensure consistency across environments.\n",
      "  - Deploy it as a microservice on a cloud platform (e.g., AWS Lambda, Google Cloud Run, Azure Container Apps) with an API endpoint.\n",
      "  - Or, integrate it directly into a larger financial application backend.\n",
      "\n",
      "4.2. Application Integration (Conceptual Web Interface):\n",
      "You could build a simple web front-end using frameworks like Streamlit or Gradio for a user-friendly interface.\n",
      "  - The web interface would send user queries to your deployed prompt optimization service.\n",
      "  - The service would return the optimized prompt's output (from the LLM simulation), which the web UI displays.\n",
      "  - Example (pseudo-code for Streamlit):\n",
      "\n",
      "# In a separate app.py file:\n",
      "# import streamlit as st\n",
      "# from your_module import financial_analysis_chain # Assuming you packaged your chain\n",
      "\n",
      "# st.title(\"Financial Prompt Optimizer Demo\")\n",
      "# user_input = st.text_area(\"Enter your financial analysis request:\")\n",
      "\n",
      "# if st.button(\"Analyze\"):\n",
      "#     if user_input:\n",
      "#         with st.spinner(\"Optimizing and Analyzing...\"):\n",
      "#             result = financial_analysis_chain.invoke(user_input)\n",
      "#         st.subheader(\"Optimized LLM Output:\")\n",
      "#         try:\n",
      "#             st.json(json.loads(result))\n",
      "#         except json.JSONDecodeError:\n",
      "#             st.code(result)\n",
      "#     else:\n",
      "#         st.warning(\"Please enter a request.\")\n",
      "\n",
      "\n",
      "4.3. Monitoring & Maintenance (Crucial Role of LangSmith):\n",
      "  - **LangSmith for Monitoring:** This is where LangSmith truly shines in a production environment.\n",
      "    - All runs (prompt optimization, LLM calls) are automatically logged.\n",
      "    - You can track latency, success rates, and errors for individual components.\n",
      "    - Provides a complete audit trail for compliance, showing exactly how each user request was processed.\n",
      "    - Allows for quick debugging if the LLM output is not as expected, by inspecting the optimized prompt.\n",
      "  - **Drift Detection:** Monitor changes in user query patterns. If new terms or analysis types emerge, you might need to update your `ENTITY_MAPPINGS` or `INTENT_MAPPINGS`.\n",
      "  - **Feedback Loop:** Collect user feedback on the quality and compliance of the LLM's outputs. This feedback is vital for refining the prompt optimization logic.\n",
      "  - **Periodic Updates:** Financial regulations and market conditions change. Schedule regular reviews and updates to your `COMPLIANCE_RULES` and related data to ensure continued accuracy and compliance.\n",
      "\n",
      "--- Project Complete (within Jupyter Scope) ---\n",
      "You have successfully built a foundational 'Financial Prompt Optimization Interface' with observability!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- PHASE 4: Deployment & Monitoring Considerations ---\")\n",
    "\n",
    "print(\"\\n4.1. Deployment Strategy (Conceptual):\")\n",
    "print(\"Once the prompt optimization logic is robust and tested in Jupyter, \"\n",
    "      \"for production deployment, you would typically:\")\n",
    "print(\"  - Package the `financial_prompt_optimizer` function and its dependencies \"\n",
    "      \"into a Python module/library.\")\n",
    "print(\"  - Containerize the application (e.g., using Docker) to ensure consistency across environments.\")\n",
    "print(\"  - Deploy it as a microservice on a cloud platform (e.g., AWS Lambda, Google Cloud Run, Azure Container Apps) \"\n",
    "      \"with an API endpoint.\")\n",
    "print(\"  - Or, integrate it directly into a larger financial application backend.\")\n",
    "\n",
    "print(\"\\n4.2. Application Integration (Conceptual Web Interface):\")\n",
    "print(\"You could build a simple web front-end using frameworks like Streamlit or Gradio for a user-friendly interface.\")\n",
    "print(\"  - The web interface would send user queries to your deployed prompt optimization service.\")\n",
    "print(\"  - The service would return the optimized prompt's output (from the LLM simulation), which the web UI displays.\")\n",
    "print(\"  - Example (pseudo-code for Streamlit):\")\n",
    "print(\"\"\"\n",
    "# In a separate app.py file:\n",
    "# import streamlit as st\n",
    "# from your_module import financial_analysis_chain # Assuming you packaged your chain\n",
    "\n",
    "# st.title(\"Financial Prompt Optimizer Demo\")\n",
    "# user_input = st.text_area(\"Enter your financial analysis request:\")\n",
    "\n",
    "# if st.button(\"Analyze\"):\n",
    "#     if user_input:\n",
    "#         with st.spinner(\"Optimizing and Analyzing...\"):\n",
    "#             result = financial_analysis_chain.invoke(user_input)\n",
    "#         st.subheader(\"Optimized LLM Output:\")\n",
    "#         try:\n",
    "#             st.json(json.loads(result))\n",
    "#         except json.JSONDecodeError:\n",
    "#             st.code(result)\n",
    "#     else:\n",
    "#         st.warning(\"Please enter a request.\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n4.3. Monitoring & Maintenance (Crucial Role of LangSmith):\")\n",
    "print(\"  - **LangSmith for Monitoring:** This is where LangSmith truly shines in a production environment.\")\n",
    "print(\"    - All runs (prompt optimization, LLM calls) are automatically logged.\")\n",
    "print(\"    - You can track latency, success rates, and errors for individual components.\")\n",
    "print(\"    - Provides a complete audit trail for compliance, showing exactly how each user request was processed.\")\n",
    "print(\"    - Allows for quick debugging if the LLM output is not as expected, by inspecting the optimized prompt.\")\n",
    "print(\"  - **Drift Detection:** Monitor changes in user query patterns. If new terms or analysis types emerge, \"\n",
    "      \"you might need to update your `ENTITY_MAPPINGS` or `INTENT_MAPPINGS`.\")\n",
    "print(\"  - **Feedback Loop:** Collect user feedback on the quality and compliance of the LLM's outputs. \"\n",
    "      \"This feedback is vital for refining the prompt optimization logic.\")\n",
    "print(\"  - **Periodic Updates:** Financial regulations and market conditions change. Schedule regular reviews \"\n",
    "      \"and updates to your `COMPLIANCE_RULES` and related data to ensure continued accuracy and compliance.\")\n",
    "\n",
    "print(\"\\n--- Project Complete (within Jupyter Scope) ---\")\n",
    "print(\"You have successfully built a foundational 'Financial Prompt Optimization Interface' with observability!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12c8c8-b12a-4511-b9f7-020b05cf5595",
   "metadata": {},
   "source": [
    "## Thanku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f42af-e166-4b71-b994-264f46b5e571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
